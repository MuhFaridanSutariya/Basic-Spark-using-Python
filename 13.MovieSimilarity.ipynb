{"cells":[{"cell_type":"markdown","metadata":{"id":"Gu_uAS_ycGVX"},"source":["# Tutorial: Taming Big Data With Apache Spark and Python - Hands On!\n","## Exercise 8 - Movie Similarity (Collaborative Filtering)\n","\n","*Note: this script cannot be run in Jupyter Lab (sys.argv). I use it to troubleshoot new code prior to running the .py file*\n","\n","### Setup\n","\n","FindSpark\n","\n","This will circumvent many issues with your system finding spark"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cy8wGloYV3Wt","executionInfo":{"status":"ok","timestamp":1663215069761,"user_tz":-420,"elapsed":23011,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"b4f6493c-eb74-4624-df6f-8cdf5d0a9ed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar -xvf spark-2.4.5-bin-hadoop2.7.tgz\n","!mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5"],"metadata":{"id":"LvAqitsoWYpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# Install java\n","!apt-get update -qq\n","!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null \n","\n","!pip install -q findspark\n"," \n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5\"\n","!java -version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8-EtFgSVWW-","executionInfo":{"status":"ok","timestamp":1663215307806,"user_tz":-420,"elapsed":11383,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"ba919ccf-0cf3-4825-a988-244fbac53e75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["openjdk version \"1.8.0_342\"\n","OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n","OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/bangkit-pambudi/resource-spark.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7vbC0-dXRAe","executionInfo":{"status":"ok","timestamp":1663215415080,"user_tz":-420,"elapsed":3894,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"406b29f4-2de3-46f3-b83c-270bfa104066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'resource-spark'...\n","remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 38 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (38/38), done.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNRxQsSfcGVv"},"outputs":[],"source":["import findspark\n","findspark.init()"]},{"cell_type":"markdown","metadata":{"id":"DsQADGgWcGV7"},"source":["Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwO14pbfcGWC"},"outputs":[],"source":["import sys\n","from pyspark import SparkConf, SparkContext\n","from math import sqrt"]},{"cell_type":"markdown","metadata":{"id":"fGfj8LJ6cGWH"},"source":["Set the file path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vpVXzcrcGWJ"},"outputs":[],"source":["data_folder = \"/content/resource-spark/data/ml-100k/\""]},{"cell_type":"markdown","metadata":{"id":"D546dlOxcGWL"},"source":["Create the Spark Context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1SNdI7HlcGWO"},"outputs":[],"source":["# configure your Spark context; master node is local machine\n","conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n","\n","# create a spark context object\n","sc = SparkContext(conf = conf)"]},{"cell_type":"markdown","metadata":{"id":"BF6gZUvtcGWR"},"source":["### Define Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfbWQvczcGWV"},"outputs":[],"source":["def loadMovieNames():\n","    movieNames = {} # create a dict\n","    file_to_open = data_folder + \"u.ITEM\" #file path\n","    with open(file_to_open, encoding = 'ascii', errors = 'ignore') as f: # open file\n","        for line in f:\n","            fields = line.split('|') # break the lines\n","            movieNames[int(fields[0])] = fields[1] # create key-value\n","    return movieNames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xYDP4VU9cGWb"},"outputs":[],"source":["def filterDuplicates(userRatings):\n","    ratings = userRatings[1] # the value ((movieID, rating), (movieID, rating))\n","    (movie1, rating1) = ratings[0] \n","    (movie2, rating2) = ratings[1]\n","    return movie1 < movie2 # return only those entries where movieID 2 is greater than movieID 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Tnc6766cGWi"},"outputs":[],"source":["#Python 3 doesn't let you pass arond unpacked tuples,\n","# so we explicitly extract the ratings now.\n","def makePairs(userRatings):\n","    ratings = userRatings[1] # the value ((movieID, rating), (movieID, rating))\n","    (movie1, rating1) = ratings[0]\n","    (movie2, rating2) = ratings[1]\n","    return ((movie1, movie2), (rating1, rating2)) #format so its pair of movies and pair of ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PgNr-KTycGWm"},"outputs":[],"source":["def computeCosineSimilarity(ratingPairs):\n","    numPairs = 0\n","    sum_xx = sum_yy = sum_xy = 0\n","    for ratingX, ratingY in ratingPairs:\n","        sum_xx += ratingX * ratingX\n","        sum_yy += ratingY * ratingY\n","        sum_xy += ratingX * ratingY\n","        numPairs += 1\n","    \n","    numerator = sum_xy\n","    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n","    \n","    score = 0\n","    if (denominator):\n","        score = (numerator / (float(denominator)))\n","        \n","    return (score, numPairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bY792UAdcGWp"},"outputs":[],"source":["def medianratings(ratings):\n","    import statistics\n","    temp = []\n","    for x,y in ratings:\n","        temp.append( (x, statistics.median(y)) )\n","    return temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMyWkzKbcGWt"},"outputs":[],"source":["def filterbad(rdd, key):\n","    temp = []\n","    for x in rdd.collect():\n","        if (x[1][0] in key) == True:\n","            temp.append(x)\n","    return temp"]},{"cell_type":"markdown","metadata":{"id":"4NOPEK51cGWu"},"source":["### The Program\n","\n","**1) Create a dictionary with movieID and movieNames.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOny28YacGWw","outputId":"42a4396a-b0ac-4330-8d18-85c9fe94c09c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Loading movie names...\n","Success! Your <class 'dict'> was created with 1682 entries. For instance Clerks (1994) is one of them.\n"]}],"source":["print(\"\\nLoading movie names...\")\n","nameDict = loadMovieNames()\n","\n","print(\"Success! Your\", type(nameDict), \"was created with\", len(nameDict), \"entries. For instance\", nameDict.get(42), \"is one of them.\")"]},{"cell_type":"markdown","metadata":{"id":"F-To5vRfcGW0"},"source":["**2) Bring in the movie ratings data.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ndQr91zcGW2","outputId":"25ba37ce-226e-4805-c72d-dcf7544c3ce0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.RDD'> was created with 100000 entries. \n","\n","The first five are:\n"," ['196\\t242\\t3\\t881250949', '186\\t302\\t3\\t891717742', '22\\t377\\t1\\t878887116', '244\\t51\\t2\\t880606923', '166\\t346\\t1\\t886397596']\n"]}],"source":["data = sc.textFile(data_folder + \"u.data\")\n","\n","print(\"Success! Your\", type(data), \"was created with\", data.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", data.take(5))"]},{"cell_type":"markdown","metadata":{"id":"-l2NWj_dcGW4"},"source":["**3) Key/value stores of dicts: user ID => movie ID, rating.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hCwhEXCcGW5","outputId":"cbe3fd28-9d86-46ab-993d-f8214f10f576"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 100000 entries. \n","\n","The first five are:\n"," [(196, (242, 3.0)), (186, (302, 3.0)), (22, (377, 1.0)), (244, (51, 2.0)), (166, (346, 1.0))]\n"]}],"source":["ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n","\n","print(\"Success! Your\", type(ratings), \"was created with\", ratings.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", ratings.take(5))"]},{"cell_type":"markdown","metadata":{"id":"h_7bdEvEcGW6"},"source":["**3.2) Remove Bad Movies**\n","\n","Return a list of values from the ratings Rdd. Will be a list of (movieID, rating)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6XR1oOTcGW8"},"outputs":[],"source":["list_movie_rating = list(ratings.values().collect()) # tuples list, with (movieID, rating)"]},{"cell_type":"markdown","metadata":{"id":"qcfOxe9McGW9"},"source":["Group by the movieID, with the value being a list of all ratings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngdPVoe7cGW-"},"outputs":[],"source":["from itertools import groupby\n","from operator import itemgetter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQJZpysOcGXA"},"outputs":[],"source":["# the list needs to be sorted prior to being aggregated\n","def getKey(item):\n","    return item[0]\n","\n","list_movie_rating_sort = sorted(list_movie_rating, key=getKey)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZJsekjwcGXB"},"outputs":[],"source":["list_movie_allratings = [(k, list(list(zip(*g))[1])) for k, g in groupby(list_movie_rating_sort, itemgetter(0))]  # (movieID, (rating1,rating2))"]},{"cell_type":"markdown","metadata":{"id":"DlCsxkM0cGXC"},"source":["Take the median of the ratings for each movie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XS0hXMcYcGXD","outputId":"a06665a1-be56-474c-b5b6-1a7d97c42571"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.RDD'> was created with 1682 entries. \n","\n","The first five are:\n"," [(1, 4.0), (2, 3.0), (3, 3.0), (4, 4.0), (5, 3.0)]\n"]}],"source":["rdd_movie_medianratings = sc.parallelize(medianratings(list_movie_allratings))\n","\n","result = rdd_movie_medianratings\n","\n","print(\"Success! Your\", type(result), \"was created with\", result.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", result.take(5))"]},{"cell_type":"markdown","metadata":{"id":"gxGwyMWvcGXF"},"source":["Filter out movies that have median ratings less than 3.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZYuWOkPcGXG","outputId":"24be748e-0e85-41c1-e096-6a94cb7a6fbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 1369 entries. \n","\n","The first five are:\n"," [(1, 4.0), (2, 3.0), (3, 3.0), (4, 4.0), (5, 3.0)]\n"]}],"source":["filteredbyRatings = rdd_movie_medianratings.filter(lambda x: x[1] > 2)\n","\n","result = filteredbyRatings\n","\n","print(\"Success! Your\", type(result), \"was created with\", result.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", result.take(5))"]},{"cell_type":"markdown","metadata":{"id":"GVv3g71OcGXO"},"source":["Create a key of movies that have ratings > 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88wu3bSYcGXP"},"outputs":[],"source":["key_movies = list(filteredbyRatings.keys().collect()) # list of keys, i.e., movies with ratings > 2"]},{"cell_type":"markdown","metadata":{"id":"8AF7pNQGcGXS"},"source":["Filter the ratings Rdd to remove movies with ratings < 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTYy6HaxcGXV","outputId":"7d2929e5-0a93-4def-b4a3-e8b463d8efb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.RDD'> was created with 96211 entries. \n","\n","The first five are:\n"," [(196, (242, 3.0)), (186, (302, 3.0)), (244, (51, 2.0)), (166, (346, 1.0)), (298, (474, 4.0))]\n"]}],"source":["ratings_filter_bad = sc.parallelize(filterbad(ratings, key_movies))\n","\n","result = ratings_filter_bad\n","\n","print(\"Success! Your\", type(result), \"was created with\", result.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", result.take(5))"]},{"cell_type":"markdown","metadata":{"id":"B1ewzJeOcGXW"},"source":["**4) Emit every movie rated together by the same user. Self-join to find every combination.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d3WkAxPcGXb","outputId":"dad3b40b-03a1-4668-ccf6-6ba7ccdaf575"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 19285491 entries. \n","\n","The first five are:\n"," [(186, ((302, 3.0), (302, 3.0))), (186, ((302, 3.0), (566, 5.0))), (186, ((302, 3.0), (250, 1.0))), (186, ((302, 3.0), (148, 4.0))), (186, ((302, 3.0), (263, 3.0)))]\n"]}],"source":["joinedRatings = ratings_filter_bad.join(ratings)\n","\n","print(\"Success! Your\", type(joinedRatings), \"was created with\", joinedRatings.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", joinedRatings.take(5))"]},{"cell_type":"markdown","metadata":{"id":"amLGFhU3cGXe"},"source":["**5) Filter out duplicate pairs**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53kBWXE_cGXg","outputId":"8a838137-fed1-429c-eb56-4d076d1aac75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 10050406 entries. \n","\n","The filter removed 10150406 entries.\n","\n","The first five are:\n"," [(196, ((242, 3.0), (393, 4.0))), (196, ((242, 3.0), (381, 4.0))), (196, ((242, 3.0), (251, 3.0))), (196, ((242, 3.0), (655, 5.0))), (196, ((242, 3.0), (306, 4.0)))]\n"]}],"source":["uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n","\n","print(\"Success! Your\", type(uniqueJoinedRatings), \"was created with\", uniqueJoinedRatings.count(), \"entries. \\\n","\\n\\nThe filter removed\", joinedRatings.count() - uniqueJoinedRatings.count(), \"entries.\\\n","\\n\\nThe first five are:\\n\", uniqueJoinedRatings.take(5))"]},{"cell_type":"markdown","metadata":{"id":"w0FrFVxPcGXh"},"source":["**5) Now key by (movie1, movie2) pairs**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzIh7NgZcGXi","outputId":"eaefa7ec-fb23-4659-924f-209833351d69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 10050406 entries. \n","\n","The first five are:\n"," [((242, 393), (3.0, 4.0)), ((242, 381), (3.0, 4.0)), ((242, 251), (3.0, 3.0)), ((242, 655), (3.0, 5.0)), ((242, 306), (3.0, 4.0))]\n"]}],"source":["moviePairs = uniqueJoinedRatings.map(makePairs)\n","\n","print(\"Success! Your\", type(moviePairs), \"was created with\", moviePairs.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", moviePairs.take(5))"]},{"cell_type":"markdown","metadata":{"id":"QlvVfh1HcGXj"},"source":["**6) Group by key.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b94fCHxacGXl","outputId":"5ebfda75-66e9-4f35-8a74-7e07137436f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 983206 entries. \n","\n","The first five are:\n"," [((242, 580), <pyspark.resultiterable.ResultIterable object at 0x0000024386ED1D30>), ((242, 692), <pyspark.resultiterable.ResultIterable object at 0x0000024386ED1CF8>), ((242, 428), <pyspark.resultiterable.ResultIterable object at 0x0000024386ED1BE0>), ((242, 340), <pyspark.resultiterable.ResultIterable object at 0x0000024386ED1E10>), ((393, 1241), <pyspark.resultiterable.ResultIterable object at 0x0000024387099470>)]\n"]}],"source":["moviePairRatings = moviePairs.groupByKey()\n","\n","print(\"Success! Your\", type(moviePairRatings), \"was created with\", moviePairRatings.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", moviePairRatings.take(5))"]},{"cell_type":"markdown","metadata":{"id":"ziw85DeYcGXm"},"source":["**7) Compute similarities.**\n","\n","*Save the results if desired\n","moviePairSimilarities.sortByKey()\n","moviePairSimilarities.saveAsTextFile(\"movie-sims\")*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_JliaXvcGXn","outputId":"ba2a45f2-2e69-4894-b6e5-504fc8d8003d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Your <class 'pyspark.rdd.PipelinedRDD'> was created with 983206 entries. \n","\n","The first five are:\n"," [((242, 580), (0.9443699330874624, 6)), ((242, 692), (0.9203762039948743, 18)), ((242, 428), (0.9419097988977888, 15)), ((242, 340), (0.9455404837184603, 32)), ((393, 1241), (1.0, 1))]\n"]}],"source":["moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n","\n","print(\"Success! Your\", type(moviePairSimilarities), \"was created with\", moviePairSimilarities.count(), \"entries. \\\n","\\n\\nThe first five are:\\n\", moviePairSimilarities.take(5))"]},{"cell_type":"markdown","metadata":{"id":"RppvF0vPcGXo"},"source":["Extract similarities for the movie we care about that are \"good\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOnjp8nFcGXp","outputId":"347a46c9-9538-4944-a2ce-8c9bddbf8251"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["len(sys.argv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgpoF1vzcGXs","outputId":"c8dca0e3-8252-44ec-95ea-352ff584dbd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['C:\\\\Users\\\\Andy\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\Andy\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-ec43cdaa-d7ba-4395-a03b-e4277274e23f.json']\n"]}],"source":["print(sys.argv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMHI482WcGXu","outputId":"c2485118-5593-4e8e-b964-953cad81fc57"},"outputs":[{"ename":"ValueError","evalue":"invalid literal for int() with base 10: '-f'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-52-1137dbc4b0e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcoOccurenceThreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmovieID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Filter for movies with this sim that are \"good\" as defined by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"]}],"source":["if (len(sys.argv) > 1):\n","    \n","    scoreThreshold = 0.97\n","    coOccurenceThreshold = 50\n","    \n","    movieID = int(sys.argv[1])\n","    \n","    # Filter for movies with this sim that are \"good\" as defined by \n","    # our quality thresholds above\n","    filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n","                                                  (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n","                                                  and pairSim[1][0] > scoreThreshold and pairsim[1][1] > coOccurenceThreshold)\n","    \n","    # Sort by quality score.\n","    results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending= False).take(10)\n","    \n","    print(\"Top 10 similar movies for \" + nameDict[movieID])\n","    for result in results:\n","        (sim, pair) = result\n","        # Display the similarity result that isn't the movie we're looking at\n","        similarMovieID = pair[0]\n","        if (similarMovieID == movieID):\n","            similarMovieID == pair[1]\n","        print(nameDict[similarMovieID] + \"\\t score: \" + str(sim[0]) + \"\\t strength: \" + str(sim[1]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
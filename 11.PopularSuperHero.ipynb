{"cells":[{"cell_type":"markdown","metadata":{"id":"n200mb8abwIh"},"source":["# Tutorial: Taming Big Data With Apache Spark and Python - Hands On!\n","## Exercise 6 - Popular Super Hero\n","\n","### Setup\n","\n","FindSpark\n","\n","This will circumvent many issues with your system finding spark"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cy8wGloYV3Wt","executionInfo":{"status":"ok","timestamp":1663215069761,"user_tz":-420,"elapsed":23011,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"b4f6493c-eb74-4624-df6f-8cdf5d0a9ed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar -xvf spark-2.4.5-bin-hadoop2.7.tgz\n","!mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5"],"metadata":{"id":"LvAqitsoWYpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# Install java\n","!apt-get update -qq\n","!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null \n","\n","!pip install -q findspark\n"," \n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5\"\n","!java -version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8-EtFgSVWW-","executionInfo":{"status":"ok","timestamp":1663215307806,"user_tz":-420,"elapsed":11383,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"ba919ccf-0cf3-4825-a988-244fbac53e75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["openjdk version \"1.8.0_342\"\n","OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n","OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/bangkit-pambudi/resource-spark.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7vbC0-dXRAe","executionInfo":{"status":"ok","timestamp":1663215415080,"user_tz":-420,"elapsed":3894,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"406b29f4-2de3-46f3-b83c-270bfa104066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'resource-spark'...\n","remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 38 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (38/38), done.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bud-GxVcbwJG"},"outputs":[],"source":["import findspark\n","findspark.init()"]},{"cell_type":"markdown","metadata":{"id":"CN3MpPdmbwJJ"},"source":["Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXRzGQ2qbwJQ"},"outputs":[],"source":["from pyspark import SparkConf, SparkContext"]},{"cell_type":"markdown","metadata":{"id":"WeqO6CvxbwJT"},"source":["Set the file path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvQjRWWxbwJV"},"outputs":[],"source":["data_folder = \"/content/resource-spark/data/\""]},{"cell_type":"markdown","metadata":{"id":"MzraVoQbbwJZ"},"source":["Create the Spark Context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZT-3I_hbwJb"},"outputs":[],"source":["# configure your Spark context; master node is local machine\n","conf = SparkConf().setMaster(\"local\").setAppName(\"PopularHero\")\n","\n","# create a spark context object\n","sc = SparkContext(conf = conf)"]},{"cell_type":"markdown","metadata":{"id":"3x88dGXYbwJd"},"source":["### Load the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84lH5GK5bwJh"},"outputs":[],"source":["# path to file of interest\n","file01_to_open = data_folder + \"marvel-names.txt\" # hero IDs\n","file02_to_open = data_folder + \"marvel-graph.txt\" # give hero ID followed by hero IDs appeared with\n","# a hero may span multiple lines\n","\n","# load the file; textFile breaks up a data file so that each row represents a single value in an RDD\n","names = sc.textFile(file01_to_open)\n","lines = sc.textFile(file02_to_open)"]},{"cell_type":"markdown","metadata":{"id":"bymNHCt1bwJj"},"source":["Define functions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBJsI7pCbwJm"},"outputs":[],"source":["# break rows; return the first element and number of elements minus 1\n","def countCoOccurences(line):\n","    elements = line.split()\n","    return (int(elements[0]), len(elements) -1)\n","\n","# break rows and return key/value of index and name\n","def parseNames(line):\n","    fields = line.split('\\\"')\n","    return (int(fields[0]), fields[1].encode(\"utf8\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQPjou-GbwJn"},"outputs":[],"source":["namesRdd = names.map(parseNames) #key-value Rdd"]},{"cell_type":"markdown","metadata":{"id":"7PPyi2eSbwJo"},"source":["### Formatting\n","\n","Return a key/value of the first element from lines and the number of elements associated with it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSkkRC_IbwJq"},"outputs":[],"source":["pairings = lines.map(countCoOccurences)"]},{"cell_type":"markdown","metadata":{"id":"oAG4htoBbwJs"},"source":["For each element (x) reduce to unique keys and sum the values of all like keys (i.e, frequency). Need to aggregate since heroes can span multiple lines."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tuAC9AiIbwJt"},"outputs":[],"source":["totalFriendsByCharacter = pairings.reduceByKey(lambda x, y : x + y)"]},{"cell_type":"markdown","metadata":{"id":"8U-aF0zEbwJv"},"source":["Reverse. Make value the key and vice versa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HoAp2yefbwJw"},"outputs":[],"source":["flipped = totalFriendsByCharacter.map(lambda xy: (xy[1],xy[0]))\n","mostPopular = flipped.max()"]},{"cell_type":"markdown","metadata":{"id":"QvXTmqjobwJx"},"source":["### Results\n","\n","Convert the ID from mostPopular(lines) to a Super Hero name."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMw8_qYLbwJy"},"outputs":[],"source":["mostPopularName = namesRdd.lookup(mostPopular[1])[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7u-VnZpzbwJz","outputId":"08481ca7-618b-498e-aec6-e75623370317"},"outputs":[{"name":"stdout","output_type":"stream","text":["b'CAPTAIN AMERICA'is the most popular superhero, with 1933 co-appearances.\n"]}],"source":["print(str(mostPopularName) + \"is the most popular superhero, with \" + \\\n","     str(mostPopular[0]) + \" co-appearances.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"QHRKaFCybfP6"},"source":["# Tutorial: Taming Big Data With Apache Spark and Python - Hands On!\n","## Exercise 5 (Part 2) - Popular Movies\n","\n","### Setup\n","\n","FindSpark\n","\n","This will circumvent many issues with your system finding spark"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cy8wGloYV3Wt","executionInfo":{"status":"ok","timestamp":1663215069761,"user_tz":-420,"elapsed":23011,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"b4f6493c-eb74-4624-df6f-8cdf5d0a9ed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar -xvf spark-2.4.5-bin-hadoop2.7.tgz\n","!mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5"],"metadata":{"id":"LvAqitsoWYpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# Install java\n","!apt-get update -qq\n","!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null \n","\n","!pip install -q findspark\n"," \n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5\"\n","!java -version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8-EtFgSVWW-","executionInfo":{"status":"ok","timestamp":1663215307806,"user_tz":-420,"elapsed":11383,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"ba919ccf-0cf3-4825-a988-244fbac53e75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["openjdk version \"1.8.0_342\"\n","OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n","OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/bangkit-pambudi/resource-spark.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7vbC0-dXRAe","executionInfo":{"status":"ok","timestamp":1663215415080,"user_tz":-420,"elapsed":3894,"user":{"displayName":"Bagas Pambudi","userId":"16684062612564440299"}},"outputId":"406b29f4-2de3-46f3-b83c-270bfa104066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'resource-spark'...\n","remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 38 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (38/38), done.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1L5UwIWbfQA"},"outputs":[],"source":["import findspark\n","findspark.init()"]},{"cell_type":"markdown","metadata":{"id":"lOUDSKD_bfQF"},"source":["Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9vFyXAdbfQH"},"outputs":[],"source":["from pyspark import SparkConf, SparkContext"]},{"cell_type":"markdown","metadata":{"id":"LCrOOukIbfQJ"},"source":["Set the file path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06SZymu6bfQL"},"outputs":[],"source":["data_folder = \"/content/resource-spark/data/ml-100k/\""]},{"cell_type":"markdown","metadata":{"id":"ABH37TnXbfQM"},"source":["Define the broadcast variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66tscJ04bfQN"},"outputs":[],"source":["def loadMovieNames():\n","    movieNames = {}\n","    with open(data_folder + \"u.ITEM\") as f:\n","        for line in f:\n","            fields = line.split('|')\n","            movieNames[int(fields[0])] = fields[1] #key movie ID and value movie name\n","    return movieNames"]},{"cell_type":"markdown","metadata":{"id":"mttMUBmqbfQP"},"source":["Create the Spark Context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgeZwbxKbfQR"},"outputs":[],"source":["# configure your Spark context; master node is local machine\n","conf = SparkConf().setMaster(\"local\").setAppName(\"PopularMovies\")\n","\n","# create a spark context object\n","sc = SparkContext(conf = conf)"]},{"cell_type":"markdown","metadata":{"id":"832ckjCPbfQS"},"source":["### Load the Data\n","\n","Broadcast the movie names."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iJnQiMpbfQU"},"outputs":[],"source":["nameDict = sc.broadcast(loadMovieNames())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEbvNni1bfQV"},"outputs":[],"source":["# path to file of interest\n","file_to_open = data_folder + \"u.data\"\n","\n","# load the file; textFile breaks up a data file so that each row represents a single value in an RDD\n","input = sc.textFile(file_to_open)"]},{"cell_type":"markdown","metadata":{"id":"TWgDMwbxbfQX"},"source":["Inspect the RDD\n","\n","*USERID, MOVIEID, RATING, Time Stamp*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-d3501mbfQY","outputId":"37e92575-9145-4f26-f5b3-768f921eceb2"},"outputs":[{"data":{"text/plain":["['99\\t98\\t5\\t885679596',\n"," '99\\t978\\t3\\t885679382',\n"," '99\\t975\\t3\\t885679472',\n"," '99\\t963\\t3\\t885679998',\n"," '99\\t931\\t2\\t886780147']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["input.top(5)"]},{"cell_type":"markdown","metadata":{"id":"090FOeBLbfQa"},"source":["### Formatting\n","\n","For each row (x) split the entry and grab the second element (movie ID) as an integer. We are also adding a value of 1 to each movie ID. This will be used to count."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7HNO4P9bfQb"},"outputs":[],"source":["movies = input.map(lambda x: (int(x.split()[1]), 1))"]},{"cell_type":"markdown","metadata":{"id":"UfRjkf6qbfQe"},"source":["For each element (x) in movies reduce to unique keys and sum the values of all like keys (i.e, frequency)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYuZG7Q0bfQf"},"outputs":[],"source":["movieCounts = movies.reduceByKey(lambda x, y: x + y)"]},{"cell_type":"markdown","metadata":{"id":"qmjJhqPMbfQg"},"source":["Reverse. Make value the key and vice versa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6z0dRfBbfQi"},"outputs":[],"source":["flipped = movieCounts.map(lambda x: (x[1],x[0]))\n","sortedMovies = flipped.sortByKey()"]},{"cell_type":"markdown","metadata":{"id":"MCsKxEbAbfQi"},"source":["### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4qDfSq5bfQj"},"outputs":[],"source":["# for the key value pairs in sortedMovies, use the movieID to return movieName from nameDict.\n","sortedMoviesWithNames = sortedMovies.map(lambda countMovie : (nameDict.value[countMovie[1]], countMovie[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2TtbSlXbfQk"},"outputs":[],"source":["results = sortedMoviesWithNames.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQQYYL56bfQl"},"outputs":[],"source":["for result in results:\n","    print (result)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}